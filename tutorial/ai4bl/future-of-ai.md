---
layout: tutorialpage
title: Future of AI
permalink: /tutorials/ai4bl/future-of-ai
path: /tutorials/ai4bl/
repo: https://github.com/fractus-io/ai4bl
tags: future, AI
---

* [Introduction](#Introduction)
* [The future of AI – beyond expectation](#TheFutureOfAIBeyondExpectation)
* [Computing Power](#ComputingPower)
* [Emerging Technology](#EmergingTechnology)
* [Assistants will become predictive](#AssistantsWillBecomePredictive)
* [Affective Computing](#AffectiveComputing) 
* [Changing Professions](#ChangingProfessions) 
* [Let’s get digital](#LetsGetDigital)


###  <a id="Introduction"></a>Introduction 

Artificial Intelligence (AI) is not a new innovation, although it certainly feels like it. 
Its origins are usually dated back to the 1920s when the term “robot” was first coined but it came into prominence during the Second World War 
thanks to Turing and the cracking of the Enigma code.  
Between the 1970s and the new Millennium, it struggled to gain traction as there simply wasn’t enough data for it to develop meaning nobody was 
willing to invest. However, the 21st century has seen a huge resurgence and since 2010, AI has dramatically changed everyday life. 

If we think about some of the things we do today, many didn’t even exist 10 or 15 years ago. 
We use Smartphones, check our social media, search using Google, talk to Alexa, stream on Netflix, listen to music on Spotify, 
buy products from Amazon, turn our lights from an App, catch Pokemon on the streets, play virtual reality games from our home, 
get an Uber or order food from Deliveroo. All these things are standard and show how far we have come in a short space of time. 
Every single one of them has a foundation of data and artificial intelligence. 

Whilst AI has brought us these amazing innovations, they are not that exciting anymore. If we expect Alexa to respond to voice commands, 
the fact that the technology is starting to do that better is great but not really a new development. 
A lot of the technology we have talked about falls into a machine learning application, ones that use data to make decisions. 
Google returns webpages that it predicts are most likely to be relevant and Netflix uses data to give us the shows it predicts we will like. 
This idea has become an expectation rather than an innovation. So, what’s next?


###  <a id="TheFutureOfAIBeyondExpectation"></a>The future of AI – beyond expectation

Experts in the field are primarily focusing on artificial general intelligence (AGI). 
Am AGI machine is one which can perform any cognitive task that a human can. Whilst the technology we have is amazing and useful, it is not cognitive, 
it does not have a concept of the world or a conscious mind if you will. 
Existing AI would not be able to pass the Turing test in which a computer must prove its intelligence as indistinguishable from that of a human. 
That is the goal for AGI and the future aims to move us closer to that point. 
Many believe that could be in the next 5 to 10 years whereas other would suggest 20 to 30 years is more accurate. 

A machine with AGI would be able to perform any task that a human being can do without being programmed to do so. 
For example, if asks to hammer a nail it would simply start guessing at a few things and continue to fail until it got it right. 
The basis of AGI would be trial and error, the same as when a human learns to walk for example. 
We should probably remember that scientists don’t even fully understand the human brain yet, let alone training a machine to do the same.


###  <a id="ComputingPower"></a>Computing Power 

One of the limitations to further development has been the lack of computer power available. 
Some of the aforementioned slow periods have also been caused by a lack of data to work with. 
For AI to get close to the intelligence of a human brain, we need what is known as quantum computing. 
Whilst the technology has been released by the likes of IBM, it is still very much in its infancy and we don’t know if they will become 
mainstream quickly. 

What this means is that whilst AI might be able to look at images of cars and build the models, it is some way off being creative enough to 
come up with its own ideas for building a car like a human would. 

###  <a id="EmergingTechnology"></a>Emerging Technology

Whilst AGI might not be imminent, advances in cloud technology, edge computing and Big Data platforms should bridge the gap between AI and robotics. 
These technologies are helping to process data faster and more effectively meaning robots can make better decisions and become more useful. 
For example, AI powered robots can carry out dangerous tasks safe in the knowledge they know what they are doing through existing datasets. 
Machine learning won’t just power Google, Facebook and Netflix but also more practical events that make our lives safer. 

###  <a id="AssistantsWillBecomePredictive"></a>Assistants will become predictive


As it stands, Alexa and Google Home respond to the commands we give them. What if they were able to start predicting what we needed? 
The same applies to other smart home devices. For example, a smart refrigerator can work out when you run out of milk and order some to be 
delivered to your day without any intervention. 
Instead of asking Alexa to turn off the lights, smarter assistants will know when you need events to happen. 
As assistants gather data, they are becoming intelligent enough to be predictive.

###  <a id="AffectiveComputing"></a>Affective Computing 


Emotional intelligence is something that AI traditionally lacks. If you say the same thing to Alexa in a happy tone or a sad tone, 
you receive the same response. Affective computing is a field that studies speech or body language and images to recognize our needs. 
For example, conversational chatbots can respond differently based on how we speak or type. 
This is done by monitoring pauses on speech or pitch of voice as a measure of emotion. The aim is to start making devices appear more human. 

###  <a id="ChangingProfessions"></a>Changing Professions 

Given the fact that AI can diagnose medical conditions through image scanning and data we will start to see changes in healthcare. 
Doctors will be able to care for patients rather than spending time on diagnosing them because AI can carry out the task in a split second. 
AI can also review contracts, provide measurements for construction or pay out insurance claims. 
Professional interactions will slowly evolve over the next few years. 

###  <a id="LetsGetDigital"></a>Let’s get digital 

Let’s get digital
Everything will be digital. Technology such as Blockchain can be used to verify our identity so we don’t need to carry ID cards. 
The movement towards cryptocurrency like Bitcoin will continue. 
Ultimately, we will interact digitally making everyday life far more efficient than it is today. 

